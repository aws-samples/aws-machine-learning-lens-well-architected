{
    "schemaVersion": "2021-11-01",
    "name": "AWS Well-Architected Machine Learning Lens V3.0 - Rel.2023-07-05",
    "description": "The Machine Learning Lens for the AWS Well-Architected Framework is a collection of customer-proven design principles and best practices for ensuring ML workloads on AWS are well-architected. Use this custom lens as a supplement to the AWS Well-Architected Framework. Source: https://github.com/aws-samples/aws-machine-learning-lens-well-architected",
    "author": "Amit Lulla",
    "pillars": [
        {
            "id": "ML_ops",
            "name": "Operational excellence",
            "questions": [
                {
                    "id": "ML_ops1",
                    "title": "How does your organizational structure and culture support your business outcomes?",
                    "description": "Organizational structure and organizational culture have a direct impact on business outcomes. Your teams must understand their part in achieving business outcomes. Teams need to understand their roles in the success of other teams, the role of other teams in their success, and have shared goals. Understanding responsibility, ownership, how decisions are made, and who has authority to make decisions will help focus efforts and maximize the benefits from your teams.",
                    "helpfulResource": {
                        "displayText": "Organizational structure and organizational culture have a direct impact on business outcomes. Your teams must understand their part in achieving business outcomes. Teams need to understand their roles in the success of other teams, the role of other teams in their success, and have shared goals. Understanding responsibility, ownership, how decisions are made, and who has authority to make decisions will help focus efforts and maximize the benefits from your teams.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-01.html"
                    },
                    "choices": [
                        {
                            "id": "ops1_1",
                            "title": "Develop the right skills with accountability and empowerment",
                            "helpfulResource": {
                                "displayText": "Artiﬁcial intelligence (AI) has many diﬀerent and growing branches, such as machine learning, deep learning, and computer vision. Given the complexity and fast-growing nature of ML technologies, plan to hire specialists with the understanding that additional training will be needed as ML evolves. Keep teams learning new skills, engaged, and motivated while encouraging accountability and empowerment at all times. Building ML models is a complex and iterative process that can infuse bias or unfair predictions against a certain entity. It's important to promote and enforce the ethical use of AI across enterprises.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-01.html"
                            },
                            "improvementPlan": {
                                "displayText": "Develop the right skills with accountability and empowerment",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-01.html"
                            }
                        },
                        {
                            "id": "ops1_2",
                            "title": "Establish ML roles and responsibilities",
                            "helpfulResource": {
                                "displayText": "Understand the roles, responsibilities, ownership, and required interactions across teams to maximize overall eﬀectiveness. An ML project typically consists of multiple roles, with deﬁned tasks and responsibilities for each. In many cases, the separation of roles and responsibilities is not clear and there is overlap.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-04.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish ML roles and responsibilities",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-04.html"
                            }
                        },
                        {
                            "id": "ops1_3",
                            "title": "Discuss and agree on the level of model explainability",
                            "helpfulResource": {
                                "displayText": "Discuss and agree with the business stakeholders on the acceptable level of model explainability required for the use case. Use the agreed level as a metric for evaluations and tradeoﬀ analysis across the ML lifecycle. Explainability can help with understanding the cause of a prediction, auditing, and meeting regulatory requirements. It can be useful for building trust ensuring that the model is working as expected.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-02.html"
                            },
                            "improvementPlan": {
                                "displayText": "Discuss and agree on the level of model explainability",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-02.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ops1_1 && ops1_2 && ops1_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ops1_1) || (!ops1_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_ops2",
                    "title": "How do you plan for continuous development and improvement?",
                    "description": "Use tools and processes that enable continuous improvement to improve the effectiveness and efficiency of your operations.",
                    "helpfulResource": {
                        "displayText": "Use tools and processes that enable continuous improvement to improve the effectiveness and efficiency of your operations.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-06.html"
                    },
                    "choices": [
                        {
                            "id": "ops2_1",
                            "title": "Establish model improvement strategies",
                            "helpfulResource": {
                                "displayText": "Plan improvement drivers for optimizing model performance before ML model development starts. Examples of improvement drivers include: collecting more data, cross-validation, feature engineering, tuning hyperparameters, and ensemble methods.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-06.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish model improvement strategies",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-06.html"
                            }
                        },
                        {
                            "id": "ops2_2",
                            "title": "Establish feedback loops across ML lifecycle phases",
                            "helpfulResource": {
                                "displayText": "Establish a feedback mechanism to share and communicate successful development experiments, analysis of failures, and operational activities. This facilitates continuous improvement on future iterations of the ML workload. ML feedback loops are driven by model drifts and requires ML practitioners to analyze and revisit monitoring and retraining strategies over time. ML feedback loops allow experimentation with data augmentation, and different algorithms and training approaches until an optimal outcome is achieved. Document your ﬁndings to identify key learnings and improve processes over time.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-08.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish feedback loops across ML lifecycle phases",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-08.html"
                            }
                        },
                        {
                            "id": "ops2_3",
                            "title": "Establish a lineage tracker system",
                            "helpfulResource": {
                                "displayText": "Maintain a system that tracks changes for each release. These changes include documentation, environment, model, data, code, and infrastructure. Having this system allows you to go back and quickly reproduce a problem on a prior release, allowing rollbacks and reproducibility.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish a lineage tracker system",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-07.html"
                            }
                        },
                        {
                            "id": "ops2_4",
                            "title": "Create tracking and version control mechanisms",
                            "helpfulResource": {
                                "displayText": "Due to its exploratory and iterative nature, it’s easy to lose track of ML model development and its evolution. You need to experiment with multiple combinations of data, algorithms, and parameters, all while observing the impact of incremental changes on model accuracy. Log and track your model experiments with configuration settings and hyperparameters. Document and version control any data processing-related ﬁndings, processes, and improvement to enable easier future referencing and reuse. Use a model registry to register and version control your ML models. Automate your model deployment with CI/CD processes. To learn more about knowledge management, refer the best practice documented in OPS11-BP04",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-11.html"
                            },
                            "improvementPlan": {
                                "displayText": "Create tracking and version control mechanisms",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-11.html"
                            }
                        },
                        {
                            "id": "ops2_5",
                            "title": "Profile data to improve quality",
                            "helpfulResource": {
                                "displayText": "Proﬁle data to use data characteristics like distribution, descriptive statistics, data types, and data patterns. Review source data for content and quality. Filter out or correct any data not passing the reviews. This will contribute to quality improvement.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-10.html"
                            },
                            "improvementPlan": {
                                "displayText": "Profile data to improve quality",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-10.html"
                            }
                        },
                        {
                          "id": "ops2_6",
                          "title": "Monitor model compliance to business requirements",
                          "helpfulResource": {
                              "displayText": "Machine learning models degrade over time due to changes in the real world, such as data drift and concept drift. If not monitored, these changes could lead to models becoming inaccurate or even obsolete over time. It’s important to have a periodic monitoring process in place to make sure that your ML models continue to comply to your business requirements, and that deviations are captured and acted upon promptly.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-03.html"
                          },
                          "improvementPlan": {
                              "displayText": "Monitor model compliance to business requirements",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-03.html"
                          }
                      }
                    ],
                    "riskRules": [
                        {
                            "condition": "ops2_1 && ops2_2 && ops2_3 && ops2_4 && ops2_5 && ops2_6",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ops2_1) || (!ops2_2) || (!ops2_3) || (!ops2_4) || (!ops2_6)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_ops3",
                    "title": "How do you manage scalable development and deployment? ",
                    "description": "Adopt approaches that improve the flow of changes into production, that enable refactoring, fast feedback on quality, and bug fixing. These accelerate beneficial changes entering production, limit issues deployed, and enable rapid identification and remediation of issues introduced through deployment activities.",
                    "helpfulResource": {
                        "displayText": "Adopt approaches that improve the flow of changes into production, that enable refactoring, fast feedback on quality, and bug fixing. These accelerate beneficial changes entering production, limit issues deployed, and enable rapid identification and remediation of issues introduced through deployment activities.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-12.html"
                    },
                    "choices": [
                        {
                            "id": "ops3_1",
                            "title": "Automate operations through MLOps and CI/CD",
                            "helpfulResource": {
                                "displayText": "Automate ML workload operations using infrastructure as code (IaC) and conﬁguration as code (CaC). Select appropriate MLOps mechanisms to orchestrate your ML workflows and integrate with CI/CD pipelines for automated deployments. This approach ensures consistency across your staging and production deployment environments. Enable model observability and version control across your hosting infrastructure.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-12.html"
                            },
                            "improvementPlan": {
                                "displayText": "Automate operations through MLOps and CI/CD",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-12.html"
                            }
                        },
                        {
                            "id": "ops3_2",
                            "title": "Synchronize architecture and configuration, and check for skew across environments",
                            "helpfulResource": {
                                "displayText": "Ensure that all systems and conﬁgurations are identical across development and deployment phases. Otherwise, the same algorithm can result in diﬀerent inference results depending on diﬀerences in system architectures. Ensure that the model gets the same range of accuracy in development, staging, and production environments. Perform this check as part of the normal promotion process.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-16.html"
                            },
                            "improvementPlan": {
                                "displayText": "Synchronize architecture and configuration, and check for skew across environments",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-16.html"
                            }
                        },
                        {
                            "id": "ops3_3",
                            "title": "Establish reliable packaging patterns to access approved public libraries",
                            "helpfulResource": {
                                "displayText": "Establish reliable patterns for data scientists to access approved public libraries by creating separate kernels for common ML frameworks. Examples of such common ML frameworks include TensorFlow, PyTorch, Scikit-learn, and Keras. This includes using internal repositories to give access to public libraries and creating separate kernels for common ML frameworks.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-13.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish reliable packaging patterns to access approved public libraries",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-13.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ops3_1 && ops3_2 && ops3_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ops3_1) || (!ops3_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_ops4",
                    "title": "How do you understand the operational health of your ML workload?",
                    "description": "Define, capture, and analyze operations metrics to gain visibility to workload and operations events so that you can take appropriate action.",
                    "helpfulResource": {
                        "displayText": "Define, capture, and analyze operations metrics to gain visibility to workload and operations events so that you can take appropriate action.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-14.html"
                    },
                    "choices": [
                        {
                            "id": "ops4_1",
                            "title": "Establish deployment environment metrics",
                            "helpfulResource": {
                                "displayText": "Measure machine learning operations metrics to determine the performance of a deployed environment. These metrics include memory and CPU/GPU usage, disk utilization, ML endpoint invocations, and latency.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-14.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish deployment environment metrics",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-14.html"
                            }
                        },
                        {
                            "id": "ops4_2",
                            "title": "Prepare an ML profile template",
                            "helpfulResource": {
                                "displayText": "Prepare an ML proﬁle template to capture workload artifacts across ML lifecycle phases. The template helps enable evaluating the current maturity status of a workload and plan for improvements accordingly. Artifact examples to capture for the deployment phase include: model instance size, model update schedule, and model deployment location. This template should have artifact metrics with thresholds to evaluate and rank the level of maturity. Enable the ML proﬁle template to reﬂect workload maturity status with snapshots of existing proﬁles, and alternative target proﬁles. Provide documentation with rationale for choosing one option over another that meets the business requirements.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-05.html"
                            },
                            "improvementPlan": {
                                "displayText": "Prepare an ML profile template",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-05.html"
                            }
                        },
                        {
                            "id": "ops4_3",
                            "title": "Enable model observability and tracking",
                            "helpfulResource": {
                                "displayText": "Establish model monitoring mechanisms to identify and proactively avoid any inference issues. ML models can degrade in performance over time due to drifts. Monitor metrics that are attributed to your model’s performance. For real time inference endpoints, measure the operational health of the underlying compute resources hosting the endpoint and the health of endpoint responses. Establish lineage to trace hosted models back to versioned inputs and model artifacts for analysis.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-15.html"
                            },
                            "improvementPlan": {
                                "displayText": "Enable model observability and tracking",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-15.html"
                            }
                        },
                        {
                          "id": "ops4_4",
                          "title": "Review fairness and explainability",
                          "helpfulResource": {
                              "displayText": "Establish model endpoint monitoring. Identify and react to any potential issues or opportunities for improvement. Monitor metrics that measure the operational health of the underlying compute resources hosting the endpoint and the health of endpoint responses. Ensure traceability of hosting metrics back to versioned inputs for analysis.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-09.html"
                          },
                          "improvementPlan": {
                              "displayText": "Enable monitoring health of model endpoint",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-09.html"
                          }
                      }
                    ],
                    "riskRules": [
                        {
                            "condition": "ops4_1 && ops4_2 && ops4_3 && ops4_4",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ops4_3)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "ML_sec",
            "name": "Security",
            "questions": [
                {
                    "id": "ML_sec1",
                    "title": "How do you control access to your ML workload?",
                    "description": "Identity and access management are key parts of an information security program, ensuring that only authorized and authenticated users and components are able to access your resources, and only in a manner that you intend. Infrastructure protection encompasses control methodologies, such as defense in depth, necessary to meet best practices and organizational or regulatory obligations.  ",
                    "helpfulResource": {
                        "displayText": "Identity and access management are key parts of an information security program, ensuring that only authorized and authenticated users and components are able to access your resources, and only in a manner that you intend. Infrastructure protection encompasses control methodologies, such as defense in depth, necessary to meet best practices and organizational or regulatory obligations.  ",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html"
                    },
                    "choices": [
                        {
                            "id": "ML_sec1_1",
                            "title": "Validate ML data permissions, privacy, software, and license terms",
                            "helpfulResource": {
                                "displayText": "ML libraries and packages handle data processing, model development, training, and hosting. Establish a process to review the privacy and license agreements for all software and ML libraries needed throughout the ML lifecycle. Ensure these agreements comply with your organization’s legal, privacy, and security terms and conditions. These terms should not add any limitations on your organization’s business plans.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html"
                            },
                            "improvementPlan": {
                                "displayText": "Validate ML data permissions, privacy, software, and license terms",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html"
                            }
                        },
                        {
                            "id": "ML_sec1_2",
                            "title": "Secure data and modeling environment",
                            "helpfulResource": {
                                "displayText": "Secure any system or environment that hosts data or enables model development. Store training data in secured storage and repositories. Run data preparation in a secure cloud. Tightly control access to the destination compute instances as data moves from the data repositories to the instances. Encrypt data at rest in the storage infrastructure and in transit to the compute infrastructure.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-04.html"
                            },
                            "improvementPlan": {
                                "displayText": "Secure data and modeling environment",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-04.html"
                            }
                        },
                        {
                            "id": "ML_sec1_3",
                            "title": "Secure governed ML environment",
                            "helpfulResource": {
                                "displayText": "Protect ML operations environments using managed services with best practices including: detective and preventive guardrails, monitoring, security, and incident management. Explore data in a managed and secure development environment. Centrally manage the conﬁguration of development environments and enable self-service provisioning for the users.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-08.html"
                            },
                            "improvementPlan": {
                                "displayText": "Secure governed ML environment",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-08.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_sec1_1 && ML_sec1_2 && ML_sec1_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_sec1_1) || (!ML_sec1_2) || (!ML_sec1_3) ",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_sec2",
                    "title": "How do you control access to your ML workload?",
                    "description": "Identity and access management are key parts of an information security program, ensuring that only authorized and authenticated users and components are able to access your resources, and only in a manner that you intend. Infrastructure protection encompasses control methodologies, such as defense in depth, necessary to meet best practices and organizational or regulatory obligations.  ",
                    "helpfulResource": {
                        "displayText": "Identity and access management are key parts of an information security program, ensuring that only authorized and authenticated users and components are able to access your resources, and only in a manner that you intend. Infrastructure protection encompasses control methodologies, such as defense in depth, necessary to meet best practices and organizational or regulatory obligations.  ",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-03.html"
                    },
                    "choices": [
                        {
                            "id": "ML_sec2_1",
                            "title": "Ensure least privilege access",
                            "helpfulResource": {
                                "displayText": "Protect all resources across various phases of the ML lifecycle using the principle of least privilege. These resources include: data, algorithms, code, hyperparameters, trained model artifacts, and infrastructure. Provide dedicated network environments with dedicated resources and services to operate any individual project.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-03.html"
                            },
                            "improvementPlan": {
                                "displayText": "Ensure least privilege access",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-03.html"
                            }
                        },
                        {
                            "id": "ML_sec2_2",
                            "title": "Restrict access to intended legitimate consumers",
                            "helpfulResource": {
                                "displayText": "Use least-privileged permissions to invoke the deployed model endpoint. For consumers who are external to the workload environment, provide access via a secure API.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-12.html"
                            },
                            "improvementPlan": {
                                "displayText": "Restrict access to intended legitimate consumers",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-12.html"
                            }
                        },
                        {
                            "id": "ML_sec2_3",
                            "title": "Protect sensitive data privacy",
                            "helpfulResource": {
                                "displayText": "Protect sensitive data used in training against unintended disclosure. Identify and classify the sensitive data. Handle the sensitive data using strategies including: removing, masking, tokenizing, and principal component analysis (PCA). Document best governance practices for future reuse and references.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-05.html"
                            },
                            "improvementPlan": {
                                "displayText": "Protect sensitive data privacy",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-05.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_sec2_1 && ML_sec2_2 && ML_sec2_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_sec2_3)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_sec3",
                    "title": "How do you protect data?",
                    "description": "Before architecting any system, foundational practices that influence security should be in place. For example, data classification provides a way to categorize organizational data based on levels of sensitivity, and encryption protects data by way of rendering it unintelligible to unauthorized access. These tools and techniques are important because they support objectives such as preventing financial loss or complying with regulatory obligations.",
                    "helpfulResource": {
                        "displayText": "Before architecting any system, foundational practices that influence security should be in place. For example, data classification provides a way to categorize organizational data based on levels of sensitivity, and encryption protects data by way of rendering it unintelligible to unauthorized access. These tools and techniques are important because they support objectives such as preventing financial loss or complying with regulatory obligations.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-05.html"
                    },
                    "choices": [
                        {
                            "id": "ML_sec3_1",
                            "title": "Enforce data lineage",
                            "helpfulResource": {
                                "displayText": "Monitor and track data origins and transformations over time. Strictly control data access. Perform preventative controls, auditing, and monitoring to demonstrate data lineage. Implement integrity checks against training data to detect any unexpected deviances caused by loss, corruption, or manipulation. Data lineage enables visibility and helps tracing root cause of data processing errors.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-06.html"
                            },
                            "improvementPlan": {
                                "displayText": "Enforce data lineage",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-06.html"
                            }
                        },
                        {
                            "id": "ML_sec3_2",
                            "title": "Keep only relevant data",
                            "helpfulResource": {
                                "displayText": "Preserve data across computing environments (such as development and staging) and only store use-case relevant data to reduce data exposure risks. Implement mechanisms to enforce a lifecycle management process across the data. Decide when to automatically remove stale data.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Keep only relevant data",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-07.html"
                            }
                        },
                        {
                            "id": "ML_sec3_3",
                            "title": "Secure inter-node cluster communications",
                            "helpfulResource": {
                                "displayText": "For frameworks such as TensorFlow, it’s common to share information like coefficients as part of the inter-node cluster communications. The algorithms require that exchanged information stay synchronized across nodes. Secure this information through encryption in transit.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-09.html"
                            },
                            "improvementPlan": {
                                "displayText": "Secure inter-node cluster communications",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-09.html"
                            }
                        },
                        {
                            "id": "ML_sec3_4",
                            "title": "Protect against data poisoning threats",
                            "helpfulResource": {
                                "displayText": "Protect against data injection and data manipulation that pollutes the training dataset. Data injections can add corrupt training data that can result in incorrect model and outputs. Data manipulations can change existing data (for example, labels) that can result in inaccurate and weak predictive models. Identify and address corrupt data and inaccurate models using security methods and anomaly detection algorithms. Ensure immutability of datasets by providing protection against ransomware and malicious code in installed third-party packages.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-10.html"
                            },
                            "improvementPlan": {
                                "displayText": "Protect against data poisoning threats",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-10.html"
                            }
                        },
                        {
                          "id": "ML_sec3_5",
                          "title": "Design data encryption and obfuscation",
                          "helpfulResource": {
                              "displayText": "Consider how personal data should be protected. Field level encryption or obfuscation can be used to protect personally identifiable data.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-02.html"
                          },
                          "improvementPlan": {
                              "displayText": "Design data encryption and obfuscation",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-02.html"
                          }
                      }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_sec3_1 && ML_sec3_2 && ML_sec3_3 && ML_sec3_4 && ML_sec3_5",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_sec3_1) || (!ML_sec3_2) || (!ML_sec3_4) || (!ML_sec3_5) ",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_sec4",
                    "title": "How do you monitor, detect and protect your workload from risks and threats?",
                    "description": "You can use detective controls to identify a potential security threat or incident. They are an essential part of governance frameworks and can be used to support a quality process, a legal or compliance obligation, and for threat identification and response efforts. There are different types of detective controls.",
                    "helpfulResource": {
                        "displayText": "You can use detective controls to identify a potential security threat or incident. They are an essential part of governance frameworks and can be used to support a quality process, a legal or compliance obligation, and for threat identification and response efforts. There are different types of detective controls.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-13.html"
                    },
                    "choices": [
                        {
                            "id": "ML_sec4_1",
                            "title": "Monitor human interactions with data for anomalous activity",
                            "helpfulResource": {
                                "displayText": "Ensure that data access logging is enabled. Audit for anomalous data access events, such as access events from abnormal locations, or activity exceeding the baseline for that entity. Use services and tools that support anomalous activity alerting, and combine their use with data classiﬁcation to assess risk. Evaluate using services to aid in monitoring data access events.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-13.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor human interactions with data for anomalous activity",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-13.html"
                            }
                        },
                        {
                            "id": "ML_sec4_2",
                            "title": "Protect against adversarial and malicious activities",
                            "helpfulResource": {
                                "displayText": "Add protection inside and outside of the deployed code to detect malicious inputs that might result in incorrect predictions. Automatically detect unauthorized changes by examining the inputs in detail. Repair and validate the inputs before they are added back to the pool.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-11.html"
                            },
                            "improvementPlan": {
                                "displayText": "Protect against adversarial and malicious activities",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-11.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_sec4_1 && ML_sec4_2",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_sec4_1) || (!ML_sec4_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "ML_rel",
            "name": "Reliability",
            "questions": [
                {
                    "id": "ML_rel1",
                    "title": "How do you design your ML workload architecture to prevent failures?",
                    "description": "A reliable workload starts with upfront design decisions for both software and infrastructure. Your architecture choices will impact your workload behavior across all five Well-Architected pillars. For reliability, there are specific patterns you must follow.",
                    "helpfulResource": {
                        "displayText": "A reliable workload starts with upfront design decisions for both software and infrastructure. Your architecture choices will impact your workload behavior across all five Well-Architected pillars. For reliability, there are specific patterns you must follow.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-01.html"
                    },
                    "choices": [
                        {
                            "id": "ML_rel1_1",
                            "title": "Adopt a machine learning microservice strategy",
                            "helpfulResource": {
                                "displayText": "Where appropriate, a complex business problem can be usefully decomposed into a series of machine learning models with a loosely coupled implementation. This can be accomplished by adopting a microservice instead of a monolithic architecture. This approach replaces one large resource with multiple small resources and can reduce the impact of a single failure on the overall workload. This strategy enables distributed development and improves scalability, enabling easier change management.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-02.html"
                            },
                            "improvementPlan": {
                                "displayText": "Adopt a machine learning microservice strategy",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-02.html"
                            }
                        },
                        {
                            "id": "ML_rel1_2",
                            "title": "Use APIs to abstract change from model consuming applications",
                            "helpfulResource": {
                                "displayText": "Use a ﬂexible application and API design to abstract change from model consuming applications. Ensure that changes to an ML model are introduced with minimal or no interruption to existing workload capabilities. Minimize the changes across other downstream applications.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-01.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use APIs to abstract change from model consuming applications",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-01.html"
                            }
                        },
                        {
                            "id": "ML_rel1_3",
                            "title": "Allow automatic scaling of the model endpoint",
                            "helpfulResource": {
                                "displayText": "Implement capabilities that allow the automatic scaling of model endpoints. This helps ensure the reliable processing of predictions to meet changing workload demands. Include monitoring on endpoints to identify a threshold that initiates the addition or removal of resources to support current demand.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-12.html"
                            },
                            "improvementPlan": {
                                "displayText": "Allow automatic scaling of the model endpoint",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-12.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_rel1_1 && ML_rel1_2 && ML_rel1_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_rel1_2)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_rel2",
                    "title": "How do you design your ML workload to adopt to changes? ",
                    "description": "Controlled changes are necessary to deploy new functionality, and to ensure that the workloads and the operating environment are running known software and can be patched or replaced in a predictable manner.",
                    "helpfulResource": {
                        "displayText": "Controlled changes are necessary to deploy new functionality, and to ensure that the workloads and the operating environment are running known software and can be patched or replaced in a predictable manner.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-06.html"
                    },
                    "choices": [
                        {
                            "id": "ML_rel2_1",
                            "title": "Automate managing data changes",
                            "helpfulResource": {
                                "displayText": "Automate managing changes to training data using version control technology. This will enable reproducibility to re-create the exact version of a model in the event of a failure.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-05.html"
                            },
                            "improvementPlan": {
                                "displayText": "Automate managing data changes",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-05.html"
                            }
                        },
                        {
                            "id": "ML_rel2_2",
                            "title": "Use a data catalog",
                            "helpfulResource": {
                                "displayText": "Process data across multiple data stores using data catalog technology. An advanced data catalog service can enable ETL process integration. This approach enables more reliability and efficiency.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-03.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use a data catalog",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-03.html"
                            }
                        },
                        {
                            "id": "ML_rel2_3",
                            "title": "Use a data pipeline",
                            "helpfulResource": {
                                "displayText": "Automate the processing, movement, and transformation of data between diﬀerent compute and storage services. This automation enables data processing that is fault tolerant, repeatable, and highly available.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-04.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use a data pipeline",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-04.html"
                            }
                        },
                        {
                            "id": "ML_rel2_4",
                            "title": "Automate endpoint changes through a pipeline",
                            "helpfulResource": {
                                "displayText": "Manual change management is error prone, and incurs a high effort cost. Use automated pipelines (that integrate with a change management tracking system) to deploy changes to your model endpoints. Versioned pipeline inputs and artifacts allow you to track the changes and automatically rollback after a failed change.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-10.html"
                            },
                            "improvementPlan": {
                                "displayText": "Automate endpoint changes through a pipeline",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-10.html"
                            }
                        },
                        {
                            "id": "ML_rel2_5",
                            "title": "Ensure feature consistency across training and inference",
                            "helpfulResource": {
                                "displayText": "Ensure consistent, scalable, and highly available features between training and inference using a feature storage. This results in reducing the training-serving skew by keeping feature consistency between training and inference.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Ensure feature consistency across training and inference",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-07.html"
                            }
                        },
                        {
                            "id": "ML_rel2_6",
                            "title": "Ensure model validation with relevant data",
                            "helpfulResource": {
                                "displayText": "Put processes in place to include real and representative data for testing and validation. Data that does not include all possible patterns and scenarios will result in failures once model is in production. Check for a distribution mismatch between training, validation, and test data as well as the inference data.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-08.html"
                            },
                            "improvementPlan": {
                                "displayText": "Ensure model validation with relevant data",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-08.html"
                            }
                        },
                        {
                            "id": "ML_rel2_7",
                            "title": "Establish data bias detection and mitigation",
                            "helpfulResource": {
                                "displayText": "Detect and mitigate bias to avoid inaccurate model results. Establish bias detection methodologies at data preparation stage before training starts. Monitor, detect, and mitigate bias after the model is in production. Establish feedback loops to track the drift over time and initiate a re-training.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-09.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish data bias detection and mitigation",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-09.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_rel2_1 && ML_rel2_2 && ML_rel2_3 && ML_rel2_4 && ML_rel2_5 && ML_rel2_6 && ML_rel2_7",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_rel3",
                    "title": "How do you prepare your ML workload to manage and withstand failures?",
                    "description": "In any system of reasonable complexity, it is expected that failures will occur. Reliability requires that your workload be aware of failures as they occur and take action to avoid impact on availability. Workloads must be able to both withstand failures and automatically repair issues.",
                    "helpfulResource": {
                        "displayText": "In any system of reasonable complexity, it is expected that failures will occur. Reliability requires that your workload be aware of failures as they occur and take action to avoid impact on availability. Workloads must be able to both withstand failures and automatically repair issues.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-11.html"
                    },
                    "choices": [
                        {
                            "id": "ML_rel3_1",
                            "title": "Use an appropriate deployment and testing strategy",
                            "helpfulResource": {
                                "displayText": "Run a trade-off analysis across available and relevant deployment/testing strategies (such as blue/green, canary, shadow, and A/B testing) and select the one that meets your business requirements. Implement metrics that evaluate model performance to identify when a rollback or roll-forward is required. When architecting for rollback or roll-forward, evaluate the following for each model 1/Where is the model artifact stored? 2/Are model artifacts versioned? 3/What changes are included in each version? 4/ What version of the model is deployed for a deployed endpoint?",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-11.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use an appropriate deployment and testing strategy",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-11.html"
                            }
                        },
                        {
                            "id": "ML_rel3_2",
                            "title": "Enable CI/CD/CT automation with traceability",
                            "helpfulResource": {
                                "displayText": "Enable source code, data, and artifact version control of ML workloads to enable roll back to a speciﬁc version. Incorporate continuous integration (CI), continuous delivery (CD), and continuous training (CT) practices to ML workload operations. This will enable automation with added traceability.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Enable CI/CD/CT automation with traceability",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-07.html"
                            }
                        },
                        {
                            "id": "ML_rel3_3",
                            "title": "Ensure a recoverable endpoint with a managed version control strategy",
                            "helpfulResource": {
                                "displayText": "Ensure an endpoint responsible for hosting model predictions, and all components responsible for generating that endpoint, are fully recoverable. Some of these components include model artifacts, container images, and endpoint conﬁgurations. Ensure all required components are version controlled, and traceable in a lineage tracker system.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-13.html"
                            },
                            "improvementPlan": {
                                "displayText": "Ensure a recoverable endpoint with a managed version control strategy",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlrel-13.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_rel3_1 && ML_rel3_2 && ML_rel3_3",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_rel3_3)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "ML_perf",
            "name": "Performance efficiency",
            "questions": [
                {
                    "id": "ML_perf1",
                    "title": "How do you evaluate ML performance efficiency and plan for improvement?",
                    "description": "Cloud technologies are rapidly evolving and you must ensure that workload components are using the latest technologies and approaches to continually improve performance. You must continually evaluate and consider changes to your workload components to ensure you are meeting its performance and cost objectives. When you architect solutions, think about trade-offs to ensure an optimal approach. Depending on your situation, you could trade consistency, durability, and space for time or latency, to deliver higher performance.",
                    "helpfulResource": {
                        "displayText": "Cloud technologies are rapidly evolving and you must ensure that workload components are using the latest technologies and approaches to continually improve performance. You must continually evaluate and consider changes to your workload components to ensure you are meeting its performance and cost objectives. When you architect solutions, think about trade-offs to ensure an optimal approach. Depending on your situation, you could trade consistency, durability, and space for time or latency, to deliver higher performance.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-01.html"
                    },
                    "choices": [
                        {
                            "id": "ML_perf1_1",
                            "title": "Determine key performance indicators",
                            "helpfulResource": {
                                "displayText": "Use guidance from business stakeholders to capture key performance indicators (KPIs) relevant to the business use case. The KPIs should be directly linked to business value to guide acceptable model performance. Consider that machine learning inferences are probabilistic and will not provide exact results. Identify a minimum acceptable accuracy and maximum acceptable error in the KPIs. This helps enable achieving the required business value and manage the risk of variable results.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-01.html"
                            },
                            "improvementPlan": {
                                "displayText": "Determine key performance indicators",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-01.html"
                            }
                        },
                        {
                            "id": "ML_perf1_2",
                            "title": "Define relevant evaluation metrics",
                            "helpfulResource": {
                                "displayText": "To validate and monitor model performance, establish numerical metrics that directly relate to the KPIs. These KPIs are established in the business goal identiﬁcation phase. Evaluate whether the performance metrics accurately reﬂect the business’ tolerance for the error. For instance, false positives might lead to excessive maintenance costs in predictive maintenance use cases. Numerical metrics, such as precision and recall, would help diﬀerentiate the business requirements and be closer aligned to business value. Consider developing custom metrics that tune the model directly for the business objectives. Examples of standard metrics for ML models include: Classiﬁcation - Confusion matrix (precision, recall, accuracy, F1 score), Receiver operating characteristic (ROC)-area under curve (AUC), Logarithmic loss (log-loss); Regression - Root mean square error (RMSE), Mean absolute percentage error (MAPE)",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-03.html"
                            },
                            "improvementPlan": {
                                "displayText": "Define relevant evaluation metrics",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-03.html"
                            }
                        },
                        {
                            "id": "ML_perf1_3",
                            "title": "Evaluate model explainability",
                            "helpfulResource": {
                                "displayText": "Evaluate model performance as constrained by the explainability requirements of the business. Compliance requirements, business objectives, or both might require that the inferences from a model be directly explainable. Evaluate the explainability needs, and the trade-oﬀ between explainability and model complexity. Then select the model type or evaluation metrics. This approach provides transparency into the reasons that a particular inference was attained given the input data.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-13.html"
                            },
                            "improvementPlan": {
                                "displayText": "Evaluate model explainability",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-13.html"
                            }
                        },
                        {
                            "id": "ML_perf1_4",
                            "title": "Perform a performance trade-off analysis",
                            "helpfulResource": {
                                "displayText": "Perform alternative trade-off analysis to obtain optimal performance and accuracy for a given use-case data and business requirement. Accuracy versus complexity trade-off: The simpler a machine learning model is, the more explainable are its predictions. Deep learning predictions can potentially outperform linear regression or a decision tree algorithm, but at the cost of added complexity in interpretability and explainability. Bias versus fairness trade-oﬀ: Deﬁne a process for managing risks of bias and fairness in model performance. Business value most often aligns with models that have considered historical or sampling biases in the training data. Further consideration should be given to the disparate impact of inaccurate model predictions. For example, underrepresented groups are often more impacted by historical biases, which might perpetuate unfair practices. Bias versus variance trade-oﬀ (supervised ML): The goal is to achieve a trained model with the lowest bias versus variance tradeoﬀ for a given data set. To help overcome bias and variance errors, you can use: Cross validation, More data, Regularization, Simpler models, Dimension reduction (Principal Component Analysis), Stop training early. Precision versus recall trade-off (supervised ML): This analysis can be important when precision is more important than recall or vice versa. For example, optimization of precision is more important when the goal is to reduce false positives. However, optimization of recall is more important when the goal is to reduce false negatives. It's not possible to have both high precision and high recall—if one is increased, the other decreases. A trade-oﬀ analysis helps identify the optimal option for analysis.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-09.html"
                            },
                            "improvementPlan": {
                                "displayText": "Perform a performance trade-off analysis",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-09.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_perf1_1 && ML_perf1_2 && ML_perf1_3 && ML_perf1_4",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_perf2",
                    "title": "How do you evolve your architecture and infrastructure?",
                    "description": "The optimal solution for a particular workload varies, and solutions often combine multiple approaches. Well-architected workloads use multiple solutions and enable different features to improve performance. When you architect solutions, think about trade-offs to ensure an optimal approach. Depending on your situation, you could trade consistency, durability, and space for time or latency, to deliver higher performance.",
                    "helpfulResource": {
                        "displayText": "The optimal solution for a particular workload varies, and solutions often combine multiple approaches. Well-architected workloads use multiple solutions and enable different features to improve performance. When you architect solutions, think about trade-offs to ensure an optimal approach. Depending on your situation, you could trade consistency, durability, and space for time or latency, to deliver higher performance.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-03.html"
                    },
                    "choices": [
                        {
                            "id": "ML_perf2_1",
                            "title": "Use a modern data architecture",
                            "helpfulResource": {
                                "displayText": "Get the best insights from exponentially growing data using a modern data architecture. This architecture enables easy movement of data between a data lake and purpose-built stores including a data warehouse, relational databases, non-relational databases, ML and big data processing, and log analytics. A data lake provides a single place to run analytics across mixed data structures collected from disparate sources. Purpose-built analytics services provide the speed required for speciﬁc use cases like real-time dashboards and log analytics.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-04.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use a modern data architecture",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-04.html"
                            }
                        },
                        {
                            "id": "ML_perf2_2",
                            "title": "Use purpose-built AI and ML services and resources",
                            "helpfulResource": {
                                "displayText": "Consider how part or all of the workload could be handled by pre-built AI services or ML resources. Better performance can often be delivered more efficiently by using pre-optimized components included in AI and ML managed services. Select an optimal mix of bespoke and pre-built components to meet the workload requirements.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-02.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use purpose-built AI and ML services and resources",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-02.html"
                            }
                        },
                        {
                            "id": "ML_perf2_3",
                            "title": "Review for updated data/features for retraining",
                            "helpfulResource": {
                                "displayText": "Establish a framework to run data exploration and feature engineering at pre-determined time intervals based on data volatility and availability. New features that have not been considered in the model training can aﬀect the accuracy of model inferences.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-17.html"
                            },
                            "improvementPlan": {
                                "displayText": "Review for updated data/features for retraining",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-17.html"
                            }
                        },
                        {
                            "id": "ML_perf2_4",
                            "title": "Optimize training and inference instance types",
                            "helpfulResource": {
                                "displayText": "Determine how the model type and data velocity aﬀect the choice of training and inference instance types. Identify the right instance type that supports memory intensive training, or compute intensive training with high throughput and low latency real-time inference. The speed of model inferences is directly impacted by model complexity. Selection of high compute instances can accelerate inference speed. GPUs are often the preferred processor type to train many deep learning models. CPUs are often sufficient for the inference workloads.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-05.html"
                            },
                            "improvementPlan": {
                                "displayText": "Optimize training and inference instance types",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-05.html"
                            }
                        },
                        {
                            "id": "ML_perf2_5",
                            "title": "Explore alternatives for performance improvement",
                            "helpfulResource": {
                                "displayText": "Perform benchmarking to improve the machine learning model performance. Benchmarking in ML involves evaluation and comparison of ML workloads with different algorithms, features, and architecture resources. It enables identifying the combination with optimal performance. Options you can use when benchmarking include: 1/Use more data to broaden the statistical range and improve the success metric of the model. 2/Apply feature engineering to extract important signals in the data for the model. 3/Make alternative algorithm selections for an optimal ﬁt to the speciﬁcs of the data. 4/Ensemble methods that combine the diﬀerent advantages of multiple models. 5/Tune the hyperparameters for a given algorithm to calibrate the model for the data.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-06.html"
                            },
                            "improvementPlan": {
                                "displayText": "Explore alternatives for performance improvement",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-06.html"
                            }
                        },
                        {
                            "id": "ML_perf2_6",
                            "title": "Evaluate machine learning deployment options (cloud versus edge)",
                            "helpfulResource": {
                                "displayText": "Evaluate if machine learning applications require near-instantaneous inference results or require inference without network connectivity. Oﬀering the lowest latency possible might require the removal of costly roundtrips to the nearest API endpoints. A reduction in latency can be achieved by running the inference directly on the device itself (on the edge). A common use-case for such a requirement is predictive maintenance in factories.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-11.html"
                            },
                            "improvementPlan": {
                                "displayText": "Evaluate machine learning deployment options (cloud versus edge)",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-11.html"
                            }
                        },
                        {
                          "id": "ML_perf2_7",
                          "title": "Choose an optimal deployment option in the cloud",
                          "helpfulResource": {
                              "displayText": "If models are suitable for cloud deployment, you should determine how to deploy them for best performance efficiency according to frequency, latency, and runtime requirements in your use cases.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-12.html"
                          },
                          "improvementPlan": {
                              "displayText": "Choose an optimal deployment option in the cloud",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-12.html"
                          }
                      }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_perf2_1 && ML_perf2_2 && ML_perf2_3 && ML_perf2_4 && ML_perf2_5 && ML_perf2_6 && ML_perf2_7",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_perf3",
                    "title": "How do you monitor, review and improve ML Performance?",
                    "description": "After you implement your workload, you must monitor its performance so that you can remediate any issues before they impact your customers. Monitoring metrics should be used to raise alarms when thresholds are breached.",
                    "helpfulResource": {
                        "displayText": "After you implement your workload, you must monitor its performance so that you can remediate any issues before they impact your customers. Monitoring metrics should be used to raise alarms when thresholds are breached.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-06.html"
                    },
                    "choices": [
                        {
                            "id": "ML_perf3_1",
                            "title": "Establish a model performance evaluation pipeline",
                            "helpfulResource": {
                                "displayText": "Capture key metrics related to model performance using an end-to-end performance pipeline to evaluate the success of a model. Choose speciﬁc metrics based on the use case and the business KPIs. Sample key metrics include training or validation errors, and prediction accuracy. Speciﬁc model performance metrics include Root Mean Squared Error (RMSE), accuracy, precision, recall, F1 score, and area under the curve (AUC). Establish a fully automated performance testing pipeline system to initiate evaluation every time there is an updated model or data.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish a model performance evaluation pipeline",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-07.html"
                            }
                        },
                        {
                            "id": "ML_perf3_2",
                            "title": "Monitor, detect, and handle model performance degradation",
                            "helpfulResource": {
                                "displayText": "Model performance could degrade over time for reasons such as data quality, model quality, model bias, and model explainability. Continuously monitor the quality of the ML model in real time. Identify the right time and frequency to retrain and update the model. Conﬁgure alerts to notify and initiate actions if any drift in model performance is observed.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-15.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor, detect, and handle model performance degradation",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-15.html"
                            }
                        },
                        {
                            "id": "ML_perf3_3",
                            "title": "Establish feature statistics",
                            "helpfulResource": {
                                "displayText": "Establish key statistics to measure changes in the data that aﬀect model outcomes. The eﬀect of changes in data on model inference depends on the sensitivity of the model to data features. Analyze the feature importance and sensitivity of the model to select the features to monitor. Monitor the statistics of features that have the largest influence on inferences. Place acceptability limits on the range of data to alert when important features drift outside the statistical range of the training data. Signiﬁcant drifts in important features would suggest model re-training.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-08.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish feature statistics",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-08.html"
                            }
                        },
                        {
                            "id": "ML_perf3_4",
                            "title": "Evaluate data drift",
                            "helpfulResource": {
                                "displayText": "Understand the eﬀects of data drift on model performance. In cases where the data has drifted, the model could generate inaccurate predictions. Consider a strategy that monitors and adapts to data drift through re-training.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-14.html"
                            },
                            "improvementPlan": {
                                "displayText": "Evaluate data drift",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-14.html"
                            }
                        },
                        {
                            "id": "ML_perf3_5",
                            "title": "Establish an automated re-training framework",
                            "helpfulResource": {
                                "displayText": "Monitor the data and the model predictions. Run analyses of model performance against deﬁned metrics to identify errors due to data and concept drift. Automate model re-training to mitigate these errors on ﬁxed scheduled intervals, or when model variance reaches a deﬁned threshold. Automated model retraining can also be started as enough new data becomes available.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-16.html"
                            },
                            "improvementPlan": {
                                "displayText": "Establish an automated re-training framework",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-16.html"
                            }
                        },
                        {
                            "id": "ML_perf3_6",
                            "title": "Include human-in-the-loop monitoring",
                            "helpfulResource": {
                                "displayText": "Use human-in-the-loop monitoring to monitor model performance eﬃciently. When automating decision processes, the human labeling of model results is a reliable quality test for model inferences. Compare human labels with model inferences to estimate model performance degradation. Perform mitigation as model re-training.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-18.html"
                            },
                            "improvementPlan": {
                                "displayText": "Include human-in-the-loop monitoring",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-18.html"
                            }
                        },
                        {
                            "id": "ML_perf3_7",
                            "title": "Detect performance issues when using transfer learning",
                            "helpfulResource": {
                                "displayText": "Monitor and ensure that the inherited prediction weights from a transferred model yield the desired results. This approach helps minimize the risk of weak learning and incorrect outputs using pre-trained models.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-10.html"
                            },
                            "improvementPlan": {
                                "displayText": "Detect performance issues when using transfer learning",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlper-10.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_perf3_1 && ML_perf3_2 && ML_perf3_3 && ML_perf3_4 && ML_perf3_5 && ML_perf3_6 && ML_perf3_7",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
            "id": "ML_cost",
            "name": "Cost optimization",
            "questions": [
                {
                    "id": "ML_cost1",
                    "title": "How do you align expenditure to your business objectives and create usage awareness?",
                    "description": "The cloud makes it easier to accurately identify the usage and cost of systems, which then allows transparent attribution of IT costs to individual workload owners. This helps measure return on investment (ROI) and gives workload owners an opportunity to optimize their resources and reduce costs. The capability to attribute resource costs to the individual organization or product owners drives efficient usage behavior and helps reduce waste. Accurate cost attribution allows you to know which products are truly profitable, and allows you to make more informed decisions about where to allocate budget.",
                    "helpfulResource": {
                        "displayText": "The cloud makes it easier to accurately identify the usage and cost of systems, which then allows transparent attribution of IT costs to individual workload owners. This helps measure return on investment (ROI) and gives workload owners an opportunity to optimize their resources and reduce costs. The capability to attribute resource costs to the individual organization or product owners drives efficient usage behavior and helps reduce waste. Accurate cost attribution allows you to know which products are truly profitable, and allows you to make more informed decisions about where to allocate budget.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html"
                    },
                    "choices": [
                        {
                            "id": "ML_cost1_1",
                            "title": "Define overall return on investment (ROI) and opportunity cost",
                            "helpfulResource": {
                                "displayText": "Evaluate the opportunity cost of ML for each use case to solve the business problem. Ensure cost eﬀective decisions are made with respect to long-term resource allocation. Minimize the possible future risks and failures through upfront understanding of the ML development process and its resource requirements. Adopt automation and optimization that can result in reduced cost and improved performance.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html"
                            },
                            "improvementPlan": {
                                "displayText": "Define overall return on investment (ROI) and opportunity cost",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html"
                            }
                        },
                        {
                            "id": "ML_cost1_2",
                            "title": "Identify if machine learning is the right solution",
                            "helpfulResource": {
                                "displayText": "Evaluate if there are alternatives, such as a simple rule-based approach, that could do a better job than ML. Weigh the cost of adopting ML against the opportunity cost of not leaning on ML transformation. Specialized resources, such as data scientist time or model time-to-market, might be the most expensive and constrained resources. The most cost-effective hardware choice might not be cost optimized if it constrains experimentation and development speed.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-03.html"
                            },
                            "improvementPlan": {
                                "displayText": "Identify if machine learning is the right solution",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-03.html"
                            }
                        },
                        {
                            "id": "ML_cost1_3",
                            "title": "Monitor usage and cost by ML activity",
                            "helpfulResource": {
                                "displayText": "Use cloud resource tagging to manage, identify, organize, search for, and ﬁlter resources. Tags help categorize resources by purpose, owner, environment, or other criteria. Associate costs with resources using ML activity categories, such as re-training and hosting, by using tagging to manage and optimize cost in deployment phases. Tagging can be useful for generating billing reports with breakdown of cost by associated resources.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-27.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor usage and cost by ML activity",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-27.html"
                            }
                        },
                        {
                            "id": "ML_cost1_4",
                            "title": "Monitor Return on Investment for ML models",
                            "helpfulResource": {
                                "displayText": "Once a model is deployed into production, establish a reporting capability to track the value which is being delivered. For example: 1/if a model is used to support customer acquisition - how many new customers are acquired and what is their spend when the model’s advice is used compared with a baseline. 2/if a model is used to predict when maintenance is needed - what savings are being made by optimizing the maintenance cycle. Effective reporting will enable you to compare the value delivered by an ML model against the ongoing execution cost and to take appropriate action. If the ROI is very positive, are there ways in which this might be scaled, to similar challenges for example. If the ROI is negative, could this be addressed by remedial action such as reducing the model latency by using server less inference, or reducing the run time cost by changing the compromise between model accuracy and model complexity, or layering in an additional simpler model to triage or filter the cases that are submitted to the full model.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-28.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor Return on Investment for ML models",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-28.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_cost1_1 && ML_cost1_2 && ML_cost1_3 && ML_cost1_4",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "(!ML_cost1_2) || (!ML_cost1_4)",
                            "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_cost2",
                    "title": "How do you ensure cost-effective resource selection and usage?",
                    "description": "Using the appropriate instances, resources, tools and services for your workload is key to cost savings. Appropriate service selection can also reduce usage and costs.",
                    "helpfulResource": {
                        "displayText": "Using the appropriate instances, resources, tools and services for your workload is key to cost savings. Appropriate service selection can also reduce usage and costs.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-12.html"
                    },
                    "choices": [
                        {
                            "id": "ML_cost2_1",
                            "title": "Select an optimal ML framework",
                            "helpfulResource": {
                                "displayText": "Organize, track, compare and evaluate machine learning (ML) experiments and model versions. Identify the most cost-eﬀective and optimal combination of instance types and ML frameworks. Examples of ML frameworks include TensorFlow, PyTorch, and Scikit-learn.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-12.html"
                            },
                            "improvementPlan": {
                                "displayText": "Select an optimal ML framework",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-12.html"
                            }
                        },
                        {
                            "id": "ML_cost2_2",
                            "title": "Select optimal algorithms",
                            "helpfulResource": {
                                "displayText": "Identify the basic machine learning paradigm that addresses your ML problem type. Basic machine learning paradigms include: supervised learning, unsupervised learning and reinforcement learning. Identify the acceptable level of tradeoﬀ between explainability and success metrics per business requirements. Run prototypes and experiments to explore high performing algorithms. Select the optimal cost-efficient algorithms that meet all the business requirements. Improved runtime performance of a tuned algorithm within business requirements, is one step towards optimizing the cost of ML.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-22.html"
                            },
                            "improvementPlan": {
                                "displayText": "Select optimal algorithms",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-22.html"
                            }
                        },
                        {
                            "id": "ML_cost2_3",
                            "title": "Tradeoff analysis on custom versus pre-trained models",
                            "helpfulResource": {
                                "displayText": "Optimize the cost through tradeoﬀ analysis based on custom versus pre-trained models. This tradeoﬀ analysis should keep the security and performance efficiency in perspective and within the acceptable thresholds.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-04.html"
                            },
                            "improvementPlan": {
                                "displayText": "Tradeoff analysis on custom versus pre-trained models",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-04.html"
                            }
                        },
                        {
                            "id": "ML_cost2_4",
                            "title": "Use managed data labeling",
                            "helpfulResource": {
                                "displayText": "Choose a managed labeling tool that provides automation and access to cost-eﬀective labeling workforce. It should also provide ﬂexibility to choose a variable number of labelers for a given input. The tool should have a user interface, and learn to label data by itself over time.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-05.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use managed data labeling",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-05.html"
                            }
                        },
                        {
                            "id": "ML_cost2_5",
                            "title": "Use data wrangler tools for interactive analysis",
                            "helpfulResource": {
                                "displayText": "Prepare data through data wrangler tools for interactive data analysis and model building. The no-code/low-code, automation, and visual capabilities improve the productivity and reduce the cost for interactive analysis.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-06.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use data wrangler tools for interactive analysis",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-06.html"
                            }
                        },
                        {
                            "id": "ML_cost2_6",
                            "title": "Use automated machine learning",
                            "helpfulResource": {
                                "displayText": "Use automated data analyzer systems when building a model. These systems experiment with and select the best algorithm from the list of high-performing algorithms. They automatically test diﬀerent solutions and parameter settings to achieve optimal models. The automated system speeds up the process, while eliminating manual experimentation and comparisons.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-13.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use automated machine learning",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-13.html"
                            }
                        },
                        {
                              "id": "ML_cost2_7",
                              "title": "Enable data and compute proximity",
                              "helpfulResource": {
                                  "displayText": "Ensure that the Region used for training and developing models is the same as the one used for data. This approach helps minimize the time and cost of transferring data to the computation environment.",
                                  "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-21.html"
                              },
                              "improvementPlan": {
                                  "displayText": "Enable data and compute proximity",
                                  "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-21.html"
                              }
                        },
                        {
                            "id": "ML_cost2_8",
                            "title": "Select optimal computing instance size",
                            "helpfulResource": {
                                "displayText": "Right size the training instances according to the ML algorithm used for maximum efficiency and cost reduction. Use debugging capabilities to understand the right resources to use during training. Simple models might not train faster on larger instances because they might not be able to beneﬁt from additional compute resources. These models might even train slower due to the high GPU communication overhead. Start with smaller instances and scale as necessary.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-09.html"
                            },
                            "improvementPlan": {
                                "displayText": "Select optimal computing instance size",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-09.html"
                            }
                        },
                        {
                            "id": "ML_cost2_9",
                            "title": "Use distributed training",
                            "helpfulResource": {
                                "displayText": "Enable distributed training for a faster training time, when an algorithm allows it. Use multiple instances in a training cluster. Use managed services to help ensure all training instances are automatically shut down when training is completed.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-15.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use distributed training",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-15.html"
                            }
                        },
                        {
                          "id": "ML_cost2_10",
                          "title": "Use appropriate deployment option",
                          "helpfulResource": {
                              "displayText": "Use real-time inference for low latency and ultra-high throughput for use cases with steady traffic patterns. Use batch transform for offline inference on data batches for use cases with large datasets. Deploy models at edge to optimize, secure, monitor, and maintain machine learning models on fleets of edge devices such as smart cameras, robots, personal computers, and mobile devices.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-24.html"
                          },
                          "improvementPlan": {
                              "displayText": "Use appropriate deployment option",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-24.html"
                          }
                        },
                        {
                          "id": "ML_cost2_11",
                          "title": "Explore cost effective hardware options",
                          "helpfulResource": {
                              "displayText": "Machine learning models that power AI applications are becoming increasingly complex resulting in rising underlying compute infrastructure costs. Up to 90% of the infrastructure spend for developing and running ML applications is often on inference. Look for cost-effective infrastructure solutions for deploying their ML applications in production.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-25.html"
                          },
                          "improvementPlan": {
                              "displayText": "Explore cost effective hardware options",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-25.html"
                          }
                        },
                        {
                          "id": "ML_cost2_12",
                          "title": "Right-size the model hosting instance fleet",
                          "helpfulResource": {
                              "displayText": "Use efficient compute resources to run models in production. In many cases, up to 90% of the infrastructure spend for developing and running an ML application is on inference, making it critical to use high-performance, cost-effective ML inference infrastructure. Selecting the right way to host and the right type of instance can have a large impact on the total cost of ML projects. Use automatic scaling (autoscaling) for your hosted models. Auto scaling dynamically adjusts the number of instances provisioned for a model in response to changes in your workload.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-26.html"
                          },
                          "improvementPlan": {
                              "displayText": "Right-size the model hosting instance fleet",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-26.html"
                          }
                        }
  
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_cost2_1 && ML_cost2_2 && ML_cost2_3 && ML_cost2_4 && ML_cost2_5 && ML_cost2_6 && ML_cost2_7 && ML_cost2_8 && ML_cost2_9 && ML_cost2_10 && ML_cost2_11 && ML_cost2_12",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_cost3",
                    "title": "How do you manage demand and supply resources?",
                    "description": "For a workload that has balanced spend and performance, ensure that everything you pay for is used and avoid significantly underutilizing instances. A skewed utilization metric in either direction has an adverse impact on your organization, in either operational costs (degraded performance due to overutilization), or wasted AWS expenditures (due to over-provisioning).",
                    "helpfulResource": {
                        "displayText": "For a workload that has balanced spend and performance, ensure that everything you pay for is used and avoid significantly underutilizing instances. A skewed utilization metric in either direction has an adverse impact on your organization, in either operational costs (degraded performance due to overutilization), or wasted AWS expenditures (due to over-provisioning).",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html"
                    },
                    "choices": [
                        {
                            "id": "ML_cost3_1",
                            "title": "Use managed services to reduce total cost of ownership (TCO)",
                            "helpfulResource": {
                                "displayText": "Evaluate adopting managed services and pay-per-usage. Using managed services enables organizations to operate more efficiently with reduced resources and reduced cost.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use managed services to reduce total cost of ownership (TCO)",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html"
                            }
                        },
                        {
                            "id": "ML_cost3_2",
                            "title": "Stop resources when not in use",
                            "helpfulResource": {
                                "displayText": "Stop resources that are not in use to reduce cost. For example, hosted Jupyter environments used to explore small samples of data, can be stopped when not actively in use. Where practical, commit the work, stop them, and restart when needed. The same approach can be used to stop the computing and the data storage services.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-16.html"
                            },
                            "improvementPlan": {
                                "displayText": "Stop resources when not in use",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-16.html"
                            }
                        },
                        {
                            "id": "ML_cost3_3",
                            "title": "Enable feature reusability",
                            "helpfulResource": {
                                "displayText": "Reduce duplication and the rerunning of feature engineering code across teams and projects by using feature storage. The store should have online and oﬄine storage, and data encryption capabilities. An online store with low-latency retrieval capabilities is ideal for real-time inference. An oﬄine store maintains a history of feature values and is suited for training and batch scoring.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-08.html"
                            },
                            "improvementPlan": {
                                "displayText": "Enable feature reusability",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-08.html"
                            }
                        },
                        {
                            "id": "ML_cost3_4",
                            "title": "Enable debugging and logging",
                            "helpfulResource": {
                                "displayText": "Ensure that there are sufficient logs and metrics recorded to capture the runtime and resource consumption. The collected logs and metrics can be analyzed to identify the areas for improvement. Monitor compute and data storage consumption. Instrument the machine learning code, and use debugging tools to capture metrics at runtime.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-23.html"
                            },
                            "improvementPlan": {
                                "displayText": "Enable debugging and logging",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-23.html"
                            }
                        },
                        {
                            "id": "ML_cost3_5",
                            "title": "Use managed data processing capabilities",
                            "helpfulResource": {
                                "displayText": "With managed data processing, you can use a simplified, managed experience to run your data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-07.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use managed data processing capabilities",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-07.html"
                            }
                        },
                        {
                            "id": "ML_cost3_6",
                            "title": "Setup budget and use resource tagging to track costs",
                            "helpfulResource": {
                                "displayText": "If you need visibility of your ML cost, set up budgets and consider tagging your notebook instances. Examples of tags include the name of the project, the business unit, and environment (such as development, testing, or production). Tags are useful for cost optimization and can provide a clear visibility into where money is being spent.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-20.html"
                            },
                            "improvementPlan": {
                                "displayText": "Setup budget and use resource tagging to track costs",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-20.html"
                            }
                        },
                        {
                            "id": "ML_cost3_7",
                            "title": "Monitor endpoint usage and right-size the instance fleet",
                            "helpfulResource": {
                                "displayText": "Ensure efficient compute resources are used to run models in production. Monitor your endpoint usage and right-size the instance fleet. Use automatic scaling (autoscaling) for your hosted models. Autoscaling dynamically adjusts the number of instances provisioned for a model in response to changes in your workload.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-29.html"
                            },
                            "improvementPlan": {
                                "displayText": "Monitor endpoint usage and right-size the instance fleet",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-29.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_cost3_1 && ML_cost3_2 && ML_cost3_3 && ML_cost3_4 && ML_cost3_5 && ML_cost3_6 && ML_cost3_7",
                            "risk": "NO_RISK"
                        },
                        {
                          "condition": "(!ML_cost3_6)",
                          "risk": "HIGH_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                },
                {
                    "id": "ML_cost4",
                    "title": "How do you optimize cost during model training?",
                    "description": "Using the appropriate instances, resources, tools and services for your workload is key to cost savings. Appropriate service selection can also reduce usage and costs.",
                    "helpfulResource": {
                        "displayText": "Using the appropriate instances, resources, tools and services for your workload is key to cost savings. Appropriate service selection can also reduce usage and costs.",
                        "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-11.html"
                    },
                    "choices": [
                        {
                            "id": "ML_cost4_1",
                            "title": "Select local training for small scale experiments",
                            "helpfulResource": {
                                "displayText": "Evaluate the requirements to train an ML model in the cloud versus on a local machine. Use local option when experimenting across diﬀerent algorithms and conﬁgurations with small data sizes. For large data, launch a cloud-based training cluster with one or more compute instances. Right size the compute instances in the training cluster based on the workload.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-11.html"
                            },
                            "improvementPlan": {
                                "displayText": "Select local training for small scale experiments",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-11.html"
                            }
                        },
                        {
                            "id": "ML_cost4_2",
                            "title": "Start training with small datasets",
                            "helpfulResource": {
                                "displayText": "Start experimentation with smaller datasets on a small compute instance or local system. This approach allows you to iterate quickly at low cost. After the experimentation period, scale up to train with the full dataset available on a separate compute cluster. Choose the appropriate storage layer for training data based on the performance requirements.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-17.html"
                            },
                            "improvementPlan": {
                                "displayText": "Start training with small datasets",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-17.html"
                            }
                        },
                        {
                            "id": "ML_cost4_3",
                            "title": "Use hyperparameter optimization technologies",
                            "helpfulResource": {
                                "displayText": "Use automatic hyperparameter tuning to run many training jobs and ﬁnd the best version of your model. Use the algorithm and ranges of hyperparameters that you specify. Use appropriate hyperparameter ranges, as well as metrics that are realistic and meet the business requirements.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-19.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use hyperparameter optimization technologies",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-19.html"
                            }
                        },
                        {
                            "id": "ML_cost4_4",
                            "title": "Use warm-start and checkpointing hyperparameter tuning",
                            "helpfulResource": {
                                "displayText": "Where feasible, use warm start hyperparameter tuning. Warm start can consist of using a parent job for a model trained previously or using transfer learning. Warm start of hyperparameter tuning jobs eliminates the need to start a tuning job from scratch. Create a new hyperparameter tuning job that is based on selected parent jobs or pre-trained models. Use checkpointing capabilities to restart a training job from the last saved checkpoint. Reuse previous trainings as prior knowledge, or use checkpointing to accelerate the tuning process and reduce the cost.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-18.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use warm-start and checkpointing hyperparameter tuning",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-18.html"
                            }
                        },
                        {
                            "id": "ML_cost4_5",
                            "title": "Use managed training capabilities",
                            "helpfulResource": {
                                "displayText": "Machine learning model training can be an iterative, compute intensive, and time-consuming process. Instead of using the notebook itself, which might be running on a small instance, consider offloading the training to a managed cluster of compute resources including both CPUs and GPUs to train the model.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-14.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use managed training capabilities",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-14.html"
                            }
                        },
                        {
                            "id": "ML_cost4_6",
                            "title": "Use managed build environments",
                            "helpfulResource": {
                                "displayText": "Consider using managed notebooks instead of local ones, or notebooks hosted on a server. Managed notebooks come bundled with security, network, storage, compute capabilities that take a lot of time and resources to develop locally. Managed ML build environment also makes it easy to decide the type of machine you prefer so you don’t need to manage any complex AMIs or security groups—this makes it very easy to get started. It can also provide access to GPUs and big machines with large amounts of RAM that might not be possible on a local setup.",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-10.html"
                            },
                            "improvementPlan": {
                                "displayText": "Use managed build environments",
                                "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-10.html"
                            }
                        }
                    ],
                    "riskRules": [
                        {
                            "condition": "ML_cost4_1 && ML_cost4_2 && ML_cost4_3 && ML_cost4_4 && ML_cost4_5 && ML_cost4_6",
                            "risk": "NO_RISK"
                        },
                        {
                            "condition": "default",
                            "risk": "MEDIUM_RISK"
                        }
                    ]
                }
            ]
        },
        {
          "id": "ML_sus",
            "name": "Sustainability",
            "questions": [
              {
                  "id": "ML_sus1",
                  "title": "Align sustainability goals with business objectives and create awareness",
                  "description": "Sustainability focuses on environmental impacts, especially energy consumption and efficiency, since they are important levers for architects to guide direct action on how to reduce resource usage. Define service level agreements (SLAs) that support your sustainability goals while meeting your business requirements. Define SLAs to meet business requirements, not exceed them. Make trade-offs that significantly reduce environmental impacts in exchange for acceptable decreases in service levels.",
                  "helpfulResource": {
                      "displayText": "Sustainability focuses on environmental impacts, especially energy consumption and efficiency, since they are important levers for architects to guide direct action on how to reduce resource usage. Define service level agreements (SLAs) that support your sustainability goals while meeting your business requirements. Define SLAs to meet business requirements, not exceed them. Make trade-offs that significantly reduce environmental impacts in exchange for acceptable decreases in service levels.",
                      "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-01.html"
                  },
                  "choices": [
                      {
                          "id": "ML_sus1_1",
                          "title": "Define the overall environmental impact or benefit",
                          "helpfulResource": {
                              "displayText": "Measure your workload’s impact and its contribution to the overall sustainability goals of the organization.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-01.html"
                          },
                          "improvementPlan": {
                              "displayText": "Define the overall environmental impact or benefit",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-01.html"
                          }
                      },
                      {
                          "id": "ML_sus1_2",
                          "title": "Consider AI services and pre-trained models",
                          "helpfulResource": {
                              "displayText": "Consider whether the workload needs to be developed as a custom model. Many workloads can use managed AI services accessible through an API. Using these services means that you won’t need to provision your own resources to collect, store, and process training data and to prepare, train, tune, and deploy an ML model. If adopting a fully managed AI service is not appropriate, evaluate if you can use pre-existing datasets, algorithms, or models. You can also fine-tune an existing model starting from a pre-trained model. Using pre-trained models from third parties can reduce the resources needed for data preparation and model training.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-02.html"
                          },
                          "improvementPlan": {
                              "displayText": "Consider AI services and pre-trained models",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-02.html"
                          }
                      },
                      {
                          "id": "ML_sus1_3",
                          "title": "Select sustainable regions",
                          "helpfulResource": {
                              "displayText": "Choose the Regions where you implement your workloads based on both your business requirements and sustainability goals.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-03.html"
                          },
                          "improvementPlan": {
                              "displayText": "Select sustainable regions",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-03.html"
                          }
                      },
                      {
                          "id": "ML_sus1_4",
                          "title": "Implement data lifecycle policies aligned with your sustainability goals",
                          "helpfulResource": {
                              "displayText": "Classify data to understand its significance to your workload and your business outcomes. Use this information to determine when you can move data to more energy-efficient storage or safely delete it. Define data retention periods that support your sustainability goals while meeting, but not exceeding, your business requirements.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-05.html"
                          },
                          "improvementPlan": {
                              "displayText": "Implement data lifecycle policies aligned with your sustainability goals",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-05.html"
                          }
                      },
                      {
                          "id": "ML_sus1_5",
                          "title": "Define sustainable performance criteria",
                          "helpfulResource": {
                              "displayText": "Make trade-offs between your model’s accuracy and its carbon footprint. When we focus only on the model’s accuracy, we “ignore the economic, environmental, or social cost of reaching the reported accuracy.” Because the relationship between model accuracy and complexity is at best logarithmic, training a model longer or looking for better hyperparameters only leads to a small increase in performance.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-07.html"
                          },
                          "improvementPlan": {
                              "displayText": "Define sustainable performance criteria",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-07.html"
                          }
                      },
                      {
                          "id": "ML_sus1_6",
                          "title": "Align SLAs with sustainability goals",
                          "helpfulResource": {
                              "displayText": "Define service level agreements (SLAs) that support your sustainability goals while meeting your business requirements. Define SLAs to meet your business requirements, not exceed them. Make trade-offs that significantly reduce environmental impacts in exchange for acceptable decreases in service levels.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-11.html"
                          },
                          "improvementPlan": {
                              "displayText": "Align SLAs with sustainability goals",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-11.html"
                          }
                      },
                      {
                          "id": "ML_sus1_7",
                          "title": "Measure material efficiency",
                          "helpfulResource": {
                              "displayText": "Measure efficiency of your workload in provisioned resources per unit of work, to measure not only the business success of the workload, but also its material efficiency. Use this measure as a baseline for your sustainability improvement process.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-15.html"
                          },
                          "improvementPlan": {
                              "displayText": "Measure material efficiency",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-15.html"
                          }
                      }
                  ],
                  "riskRules": [
                      {
                          "condition": "ML_sus1_1 && ML_sus1_2 && ML_sus1_3 && ML_sus1_4 && ML_sus1_5 && ML_sus1_6 && ML_sus1_7",
                          "risk": "NO_RISK"
                      },
                      {
                          "condition": "(!ML_sus1_1) || (!ML_sus1_6)",
                          "risk": "HIGH_RISK"
                      },
                      {
                          "condition": "default",
                          "risk": "MEDIUM_RISK"
                      }
                  ]
              },
              {
                  "id": "ML_sus2",
                  "title": "How do you ensure sustainable resource selection and usage?",
                  "description": "Choose algorithms that produce desired results with minimal resource usage. Continuously evaluate optmization opportunities in choosing the most efficient algorithm version, model deployment instance type, inference instances and modes of deployment along with the use of serverless pipelines where possible. Selecting the right region, resource type, storage type and inference endpoint type help in building more sustainable workloads.",
                  "helpfulResource": {
                      "displayText": "Choose algorithms that produce desired results with minimal resource usage. Continuously evaluate optmization opportunities in choosing the most efficient algorithm version, model deployment instance type, inference instances and modes of deployment along with the use of serverless pipelines where possible. Selecting the right region, resource type, storage type and inference endpoint type help in building more sustainable workloads.",
                      "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-08.html"
                  },
                  "choices": [
                      {
                          "id": "ML_sus2_1",
                          "title": "Select energy-efficient algorithms",
                          "helpfulResource": {
                              "displayText": "To minimize resource usage, replace algorithms with more efficient versions that produce the same result.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-08.html"
                          },
                          "improvementPlan": {
                              "displayText": "Select energy-efficient algorithms",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-08.html"
                          }
                      },
                      {
                          "id": "ML_sus2_2",
                          "title": "Minimize idle resources",
                          "helpfulResource": {
                              "displayText": "Adopt a managed and serverless architecture for your data pipeline so that it only provisions resources when work needs to be done. By doing so, you are not maintaining compute infrastructure 24/7 and you minimize idle resources.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-04.html"
                          },
                          "improvementPlan": {
                              "displayText": "Minimize idle resources",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-04.html"
                          }
                      },
                      {
                          "id": "ML_sus2_3",
                          "title": "Adopt sustainable storage options",
                          "helpfulResource": {
                              "displayText": "Reduce the volume of data to be stored and adopt sustainable storage options to limit the carbon impact of your workload. For artifacts like models and log files that must be kept for long-term compliance and audit requirements, use efficient compression algorithms and use energy efficient cold storage.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-06.html"
                          },
                          "improvementPlan": {
                              "displayText": "Adopt sustainable storage options",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-06.html"
                          }
                      },
                      {
                          "id": "ML_sus2_4",
                          "title": "Archive or delete unnecessary training artifacts",
                          "helpfulResource": {
                              "displayText": "Remove training artifacts that are unused and no longer required to limit wasted resources. Determine when you can archive training artifacts to more energy-efficient storage or safely delete them.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-09.html"
                          },
                          "improvementPlan": {
                              "displayText": "Archive or delete unnecessary training artifacts",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-09.html"
                          }
                      },
                      {
                          "id": "ML_sus2_5",
                          "title": "Use efficient model tuning methods",
                          "helpfulResource": {
                              "displayText": "Implement an efficient strategy to optimize hyperparameter values to minimize the resources required to complete model training. Avoid a brute force strategy wherever possible, as it tests hyperparameter values without concern for the number of resources used.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-10.html"
                          },
                          "improvementPlan": {
                              "displayText": "Use efficient model tuning methods",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-10.html"
                          }
                      },
                      {
                          "id": "ML_sus2_6",
                          "title": "Use efficient silicon",
                          "helpfulResource": {
                              "displayText": "Use the most efficient instance type compatible with your ML workload.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-12.html"
                          },
                          "improvementPlan": {
                              "displayText": "Use efficient silicon",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-12.html"
                          }
                      },
                      {
                          "id": "ML_sus2_7",
                          "title": "Optimize models for inference",
                          "helpfulResource": {
                              "displayText": "Improve efficiency of your models and thus use less resources for inference by compiling the models into optimized forms.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-13.html"
                          },
                          "improvementPlan": {
                              "displayText": "Optimize models for inference",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-13.html"
                          }
                      },
                      {
                          "id": "ML_sus2_8",
                          "title": "Deploy multiple models behind a single endpoint",
                          "helpfulResource": {
                              "displayText": "Host multiple models behind a single endpoint to improve endpoint utilization. Sharing endpoint resources is more sustainable and less expensive than deploying a single model behind one endpoint.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-14.html"
                          },
                          "improvementPlan": {
                              "displayText": "Deploy multiple models behind a single endpoint",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-14.html"
                          }
                      },
                      {
                          "id": "ML_sus2_9",
                          "title": "Retrain only when necessary",
                          "helpfulResource": {
                              "displayText": "Because of model drift, robustness requirements, or new ground truth data being available, models usually need to be retrained. Instead of retraining arbitrarily, monitor your ML model in production, automate your model drift detection and only retrain when your model’s predictive performance has fallen below defined KPIs.",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-16.html"
                          },
                          "improvementPlan": {
                              "displayText": "Retrain only when necessary",
                              "url": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsus-16.html"
                          }
                      }
                  ],
                  "riskRules": [
                      {
                          "condition": "ML_sus2_1 && ML_sus2_2 && ML_sus2_3 && ML_sus2_4 && ML_sus2_5 && ML_sus2_6 && ML_sus2_7 && ML_sus2_8 && ML_sus2_9",
                          "risk": "NO_RISK"
                      },
                      {
                          "condition": "default",
                          "risk": "MEDIUM_RISK"
                      }
                  ]
              }
            ]
        }
    ]
  }